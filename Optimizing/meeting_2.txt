If it's like my family, I definitely have no subjects. Hey Daniel here. Hello. Welcome. Welcome back here. Thanks so much. Yeah, it's great to be here. Hi Virginia. No. All right, let's let's kick off. I wanted to start out with some reminders. First, we have a book club coming up on Inspired in four weeks on August 7th. I just reread it myself. It's a good read. It's highly aligned with how I think about product management and does a good job of explaining why some of these things are important. That I also believe to be important. So it's nice to have another voice explaining all of that. So please do read that. I think I'm going to update the new hire on boarding dock and ask all new hires to read this as well so that we all. Everybody in the team is on the same page with respect to this book. Let's see. Reminder B. Remember, there's this interview spreadsheet. CS and sales have populated that with the number of customer contacts for meetings. Please do follow up on that. I want to ensure good will with that team and follow up promptly with meetings with these customers so that that team can see that we're taking advantage of it. Third reminder, we've got a little engagement survey. I'm going to run this once a month in Q3 just to take a pulse given all the change going on. Please do take a minute to fill it out. It's five you know quick questions and then one free form where you can share whatever feedback you have. Fabia didn't receive it. I'm pretty sure I went through my emails. I think I have some maybe it's on my end but I'm happy to fill it out but I didn't get it. I need to get it to you. All right, I will ask Jessica to reason that to you. Anybody else in the same condition where you did not receive it? I don't recall but is there a way to put the link to the survey in the agenda? Well, it's personal. It's tied back to your user IDs so we can track which team you're on and that kind of thing. I do believe it's anonymous but nevertheless everyone has their own custom ID. So I'll ask Jessica to send it to Fabia and Karina. Anybody else? So I just I hadn't seen it in Scott but I searched my email real quick and it looks like that's the title of the email so if you just search for that in your in your Gmail you should be able to find it if you got it. Pulse survey. Culture app. Okay. If anybody else didn't get it, please ping me. All right. Next reminder, we need we have a goal of at least three customer interviews per PM. There's an OKR issue out there. If you haven't updated it lately please do so. And remember we have three weeks until Q2 to hit our goals so please do invest the time to get those set up and get at least three done if you haven't already. Next one category maturity page last week we talked about this. Josh did a great job of creating some new views. One of which is sort of this flow chart showing how mature we're going to be at a given point in time which raised questions about whether we were forecasting that accurately. If you haven't already please go in and either confirm that it's accurate or updated. Thanks to Kenny for creating that issue. Somebody had a direction maturity page. You want to talk about that? Well, it was just me just as you were offensive. I was adding the link there. That's all just folks. It's seeing the updates there for the charts. Just check it out. So it's a good way you can give a sense for like, you know, it's hard. It's hard when it's in tabular form but when it's charted it's much easier to see like if it's achievable or not based on some of the trends. And there's also if you scroll down stays level trends as well. So you can see how your stage in particular is trending or said to be trending. So. Great. Thank you Josh. All right. Some team updates. We hired a couple more PMs. We got a good rhythm going on hiring. We hired Gabe Weaver. He originally came through the growth funnel. But we have a really strong candidate for that fourth slot. So we're going to target Gabe for a third managed PM. The charter of that team is to be defined but bottom line we're going to have a third group in the managed area and Gabe will lead that. And then Dove Hershkowitz. We just hired him as the APM monitoring. He's got a great background in monitoring and it has most recently been elastic. So thank you to everyone who's been involved in the hiring loop. I know it's taking a lot of energy from everybody but I think our hiring processes continues to pick up speed. Be to be worked with with Christie and David Sakamoto to change in the language around customer results. Just wanted to make sure you all saw that. So there's the MR. It's got on that one I just the there's a the diff highlights of what is new content I believe. And there's one section that is great. I can totally understand why we would add that about prioritized ruthlessly but then the rest is I guess a bunch of formatting changes and I don't know if there's new content in any of the dog fooding. I guess the TLDR the edition of that prioritized ruthlessly or is there some other point we were trying to make in this change? It's been a little while. I think there were a number of changes but before the handbook basically read that internal feedback is worth 10 times more than external feedback. And I understand why we want internal feedback because of dog fooding and using our own product. It's a it's a great channel for feedback but I think it was sending the message that customers weren't nearly as important as internal opinion. And both Christie and I want to move off of that position like we should be customer first and treat our own teams as a customer but let's I don't I don't want people to interpret that our own internal opinion is worth 10 times more than a customer's opinion if that makes sense. So it was mostly language wherever that showed up in the handbook. Catch it okay one comment on ahead on this is that some of the tech seems like we should focus on core competencies as opposed to new scope and like as in we should focus for example or best at. So anyway that's one thought I had on this. I don't remember that being the point of it maybe it reads that way. I don't know feel free to continue to suggest tweaks. The point was let's prioritize and do what matters most first just it's kind of what I've been preaching the whole time like let's in your area wherever that is do what matters first. Don't try to do it all at once we're going to have to work our way through. That was the point. Yeah and I don't know if this is a follow up issue and the way you described it it doesn't seem controversial but I will say there was a big discussion and a recent initiative you know from Sid and other leaders that we should heavily prioritize dog footing because there were parts there are teams within the company that were not utilizing our features and we wanted to make sure that the product team was responsive to request from them. It's a little bit different than saying it's about our internal opinion like that we should we had always said we should validate it so the clarification is good that we want to make sure it's about us saying this is in line with where we want to take the product and where we're hearing customers but if an internal customer wants it we should we should do original thinking was that we should emphasize it. I just want to like if the intent was to make sure we we're just clarifying that same position but if we're saying actually we should kind of pull back from the push for more dog footing. No I would please don't conflate the two. Okay we very much still want to dog food. I think the point is when you're thinking of customers for your thing think of our internal teams early like you can get great feedback from them they have an incentive to work with you there's very little risk in rolling out things early to them so treat them like a customer and think of our internal teams early as you're rolling something out that's still very much the message but let's not over rotate on internal feedback or internal opinion let's still see external feedback too because that's just one customer of many. Cool. Okay. Makes sense? Okay. Yeah it does. All right to see customer training discovery training coming soon. Sarah O'Donnell and her team we're going to do a bunch of sort of quick videos on a variety of customer discovery topics. So super excited for that they should start dropping any day now I think starting this week. And so we'll release those two as they come out we'll embed them in the how we work description or team page as well. All right. Number three 122 kick off feedback Josh thanks for leaving the charge I thought you did a good job of MC and sort of adding color commentary in between I thought the screenshots definitely helped there were a bunch that did not have them. I was wondering why is it just because we're not there yet on many of these? Yeah. Okay. Yeah I mean some commentary I don't know or Nicole added that yeah many of the issues we're saying we're going to do UX front end and back end in the same iteration so it hasn't started. And in some they're like I can think of a number where they're just aren't appropriate screenshots or at least there weren't screenshots or mockups created in advance. Okay. For the purposes of front end working on it because front end was going to work on it without a mockup. Okay. I'd love to get to where we're a bit ahead so that we'll have more of these earlier and hopefully the customer discovery flow will get us further ahead on that. In my case some of the features also just have no UX component. Yeah. There's no UI component that could be being shot in. It's understood. Yeah I don't expect everyone. I mean use your judgment if it doesn't need it fine but where we do need design it'd be great to get at least a month ahead so as we roll into dev we have that to offer them. Scott just a quick question to you. How do you feel about presenting like balsamic or super low-fi mockups on the kickoff call? Fine with that. Okay. Because that could be an option too for PMs that are waiting for UX to work in the same sprint. And I know that plans done a pretty good job at least in the past of kind of running ahead of UX and saying like, okay this is kind of what I think I want this to look like before spending UX cycles on making a more high-fi mockup. So just if you think it does a better job of describing it than the issue itself then use it. I think I think in some cases like a picture can be worth a thousand words. I mean no matter how many words you throw at something it's like for example one of my things that I request or I report it on for the release the kickoff meeting was expanding the Epic view in the roadmap and like those are basically just a bunch of buzzwords put together that you're like okay what does that mean expand Epic and I'm just I literally thought on that one for like 20 minutes saying how do I make this epic how do I make this issue title like more descriptive for customer value and it just came down to like that is the functionality we're adding. What does that mean? Oh here's the screenshot you can see that we're going to add a drop down you can see the issues and the children up there that are attached to that Epic. And in that case like I was like I'm so thankful I have a screenshot even though that one is actually not a high-fi mockup it's more it's more low-fi it's a little bit piece together. So yeah I think like in general there's a lot more value if we can show something like that so you know product managers you can consider that you should feel free that you know you're empowered to take a tool that you're comfortable with even if it might even be just like Google Slides and make something that gets you at least a part of the way there in terms of what you want to experience to look like. Yep perfect. 3C I thought the talk track shifted and I was definitely more a problem focused I noticed a number of speakers really trying to zero in on that which is perfect some of them could have been more problem focused I thought and so just keep keep considering that as you as you yeah it's important to be able to pitch these things in ways that people that aren't close to it can understand and so just think about that how do I explain this to someone who's cold who doesn't know a darn thing about this why should they care that getting that crystal in your in your thinking is going to be important no matter what so it's time will spend. Thanks Scott this is Kriina just to add to that if you don't mind. I think this has always been a challenge in product even before I've joined GitLab for many people is how to how to get there on some of this terminology when those of us have deep technical background. So my thought would be is there a way that you can start sharing you know or applauding good examples of this so that the product team can start to kind of ruminate on this and develop that skill if if we're not there yet. Yeah I thought Lucas were very well framed up. Those those two popped out at me is yeah that's the problem we're trying to solve. Check those out. I'll look through for some other examples. Thank you for the suggestion. All right 3D we went long. We just have a ton of speakers which I love that lots of people get a chance to speak so I'm good with that but we're going to have to we're going to have to limit the number of items probably so it looks like there's some other ideas in here perhaps themes. Yeah I mean if there are some that relate to each other you could tell a story hey we're trying to prove this and then a b and c tie back to it. I think it's okay to be pretty brief in your description as long as you're hitting what it is and if somebody's really interested they can dive deep thematic is a good idea. Recorded video if you really want to go deep maybe it's technically complex that's a great idea and then you can just cover the customer value to high level and leave the detail to the video. Watch statistics I think Josh looked this up last time I think he said there were a thousand oh there we go Kenny's putting it in so somewhere between 500 and a thousand. To kind of add to the time just a feedback I was timing myself this time and I had two features listed and I hit three minutes in 14 seconds obviously he's shortened that so when we talk about you know I think somebody mentioned doing two or coupling it down it's interesting that I landed there with the two that I chose. Yeah that feels about average but we've had how many speakers we'll probably have to be a couple minutes max for person. I mean Eric pointed this out in the next line I do think we are due for a rethink of how we're doing the kickoff because we're going to have next month we're going to have 25 people trying to give content and even at two minutes you're already gone so yeah we expand it. I will give a shout out for Jason I know because he's unfortunately created a video but I think the original intent of the kickoff was actually just as a company we had a retrospective and a kickoff a retrospective immediately followed by a kickoff and we just decided to post that on YouTube we now post a whole bunch of content on YouTube so just just having what you would normally do for your kind of like grooming or kickoff within your individual group posted to YouTube and us maybe having a specific channel for people who wanted to follow it. Anyway we should discuss it in an issue and come up with something I do think prior to next release kickoff. Just to evaluate alternatives to the format? Yeah I mean I don't even if we said every person has one minute I feel like we're doing it this service because we're now highlighting much less because we feel like we have a time constraint and need to keep it into one synchronous 30 minute block. We need to do that. Okay. Yeah I have fun. Plus one to revamping it I think I think we're trying to it's like got so many jobs right now that we're not doing a good job at any of those are one of them. But I think that feels the most important customers are internal and it's just like communicating internally about because like people have done that thing then we had like 50 people in the Zoom call alone not even considering YouTube and people were asking about what happened to YouTube link and things like that so it's well attended internally so I think there's for alignment. So yeah I'm putting it along the marketing value of like sort of like a release I mean for fictional customers it kind of feels like that we'd better off having like a webinar or live stream on the release day. Right. Yeah maybe the externally focused one would be more about what we just shipped. There was a webinar that used to happen at Cold Relaced Rader. I think I participated in a couple of those three of them back to back and they were pretty poorly attended from what my experience was and I think they actually got ended by the product marketing team for that reason. I'm sure someone from that team could actually give feedback but I think one thing about the time limit is it's really hard to motivate problems particularly like in a short amount of time particularly when they're very technical like as product categories grow in maturity and sophistication like the problems become more and more specific that we're solving and so motivating those specific reasons and why we're going after like this specific tiny piece of a very mature category it's hard to do it 30 seconds in a way that and so if we want to do that better that's going to put more more pressure on like communicating every single number of items I think. Okay thank you all for the feedback. I like the idea of creating an issue and perhaps tweaking the format before next month. I also like the idea of asking internal and external constituents with a like or don't like about the format. Yeah just one final thought on that like I love that it's a half an hour might almost even like take pick particular categories over over over uh um lengthening the time as an example just because I feel the feeling I had a feeling that if you want to watch it consistently it's going to be in that block but that's just me so like if uh you know other customers are uh you know saying send it with like the larger block then then that's the way way to go so that's that's where I love to get feedback in some fashion but get say okay you know here's how we should change it but we clearly have gone breathwise we've gone so much broader that it's going to be hard to cover all the topics in it. Okay thanks Kenny for starting the issue. James over to you for number four. Yeah I just thought I'd uh share this um for many I think many on this call haven't heard Mark Kumsbach speak about um product discovery sprints that he advocated that there's quite a number of times previously um from his experience reckoning these at a prior company um so the idea is kind of different to a uh I guess a UX discovery sprint I think Fabian linked one of the books about that where it's really focused on UX iteration and research um the product discovery sprint is more focused on kind of like actually building something iterating on something that's built and trying to get to some sort of NVC really quickly by trying to make the process more synchronous so um the source code group is going to try and do that around file by file def navigation to solve performance and usability problems um in 12.3 um and I thought it would be interesting to share that because internally we've been wrestling with like how to make this work well in async slash remote environment um so we're looking at trying to confine the participants in a specific time zone so that we can all be available with a significant amount of overlap um but that's also difficult because we have it kind of excludes automatically 50% of the team who are just geographically remote from any of their peers we only have one UX designer that's only available in the European time zone so um some interesting challenges there if it goes well we're going to try and replicate it um a release or two later on a different problem that is also really complicated and hard and we want to make progress on quickly but I'll share any findings we have and if anyone's interested in discussing that with me more um put a meeting my calendar or drop me a message this is great James by the way I think the UX team is going to run well let me just say we have the option to run one with Google Ventures who's one of our investors in that sprint book that Fabian Link 2 was written by a guy from GV they did hundreds of these things with our clients they know what they're doing so if we get a chance to do one with them we should uh we're gonna have to figure out how to do it within our async model though so whatever you learn from yours James please feed that back a super interesting topic I think if we could get good at this asynchronously that would be a breakthrough yeah I think one other interesting challenge is that the sprint sort of terminology is kind of challenging and like it's not sustainable to be doing design sprints or discovery sprints on a daily basis yeah whether or not we were in person or not it's not scalable to actually sprint all the time so choosing the right task is choosing the right time um is I think one of the other challenges I agree yeah you don't want to do this for everything because well if you follow the to the letter it takes a whole week and you're totally dedicated to it which is amazing for focus sake but you can't get anything else done so depending on how we structure this it would need to be done for things that are really big unknowns where dedicating a huge chunk of time like that is worth it and not everything clears that bar yeah I think it's also most relevant for for stages that are very in very interesting in the very beginning kind of like that tyron was like one of their biggest example for Google Ventures when they obviously like solving clinical trials for the world is like super complex problems so they just figured out what is this a thing that we can do so that we can start getting there and I think these are the problems that the design sprints use we used it pretty successfully at my last company around pricing and packaging stuff and ran a bunch of interviews with customers on that so I've seen it work all right okay Christopher number five yeah just want to call out we've over the past month we've had a significant number of outages related to .com and the effect that at least one customer revenue potential and because of that you know we've had some some focus from an executive so I encourage everybody to look at that document you kind of look through it in particular as a couple things from an engineering perspective make you aware of one is as we started infrastructure to development board where we're going to start matching issues up and trying to make sure that if that those could prioritize highly where appropriate particularly for anything that you know affects performance around these issues the other issue that I put in there was one around that's listed specifically which is around the fact of prioritizing p performance availability work so one of the significant features of this up to go recent outage last week was that the register apparently can't handle the load anymore we started digging into it we found a bunch of stuff that we hadn't checked like for instance it's an example rj unit test we're basically going and getting cached and there was no limit on the number of unit tests that could actually be cached so they were getting these like blocks of like several megabytes of data that had to basically be transferred around and read us and that's really what's affecting its performance overall from a caching service perspective so consequently Scott I said that to you I hope that's okay because it feels like it was like you need to help out when it hurts the effect of you know how do we best make sure that we get this kind of systematically going and I just want to make sure that everybody was aware and just kind of open up for discussion if there were any questions or or any feedback or early feedback on it from my perspective I added some comments to it Christopher okay I have an add a chance to look at Paul just about that problem can I ask do we and maybe Mac this is a question for you do we categorize performance issues as bugs we do have a performance label but they should be under under bugs okay yeah this is an example where oftentimes the way we treat performance is a reactionary this is trying to think about a more in a proactive way so like as an example I'll give a horrible example but when I worked at Amazon tags originally when Amazon was created tags were they were expecting this to label you know certain instances and that was it and it turns out that all customers started using like 20 and 30 or 50 tags and they're like what the heck is going on and they realize tags were being used to basically you share environmental information so the VMs could they could put the same drop a code on two different VMs and they could behave differently based on the tag which was a total novel way for customers to use it so then they had the basically limit the number of tags they could use because it wasn't scaling with the system effectively so like this is kind of another example where like I think we got to start thinking in terms of you know like when we create something new a new feature of piece of functionality like what's the cost associated with that right because like it does cost something internal and I'm not asking product managers to necessarily think in terms of the exact bytes but I am turning to think in terms of like you know what are the expectations around it because like as an example if we went back and looked at G-Unit tests and reporting you know if we said unlimited that's you know that's a tough engineering call right particularly I guess it's free right now for customers so this is a minor standing we also don't have a number of reposmire we don't have a limit on that and that that seems dangerous yeah so I guess I would comment you know I think the product team is expected to prioritize all things and to understand them deeply whether they're a security issue or a performance concern I think what you're highlighting is in order to be proactive I don't know if the product team would immediately know the impact of a proposed change but maybe that's an opportunity for our infrastructure SRE stable counterparts to be involved in vetting and looking at issues early in the pipeline to decide whether or not they would yeah or or let's say we're implementing a feature like let's say we were implementing mirroring from scratch like the first question we should be asking is is like how many how many mirrors is a customer expected to be able to support and what I want to start charging for if they get above a certain limit and you know and right now we don't and you could argue that scaling is just a much a reason for customers to start paying us as his feature sets that's that's that's that's kind of the argument I would do because those things cost money like whether we like to admit it or not yeah Christopher I would agree with you on what you're trying to sort of shape up and call out here in the sense of you know going through pages for example the performance of getting those page loads loaded is not great and I don't know if we set out originally to track some of those performance things but I think that performance and into your point can I think performance should be somewhere incorporated as we move forward and something we should be thinking about for scalability across the board because it's just as important as bringing forth that really cool thing to them is that that really cool thing works and people will stay there to use it. I think just as a cycle I think we have something the product and book that I read like a couple days ago on performance something like fast applications are like always you know like more usable and I think that's that's definitely important and I also think that githlet.com is massive I think we have 4 million users and for example for geo I know that only by actually like interacting with the infrastructure we are getting feedback on some of the performance bottlenecks that we are just not seeing otherwise right and so I think that's actually also really valuable and in that regard maybe also like again you know dog fooding these things helps and I think with the combination of CD we may hit a lot of those things at the yeah and the dog fooding thing on that front is a little confusing me I met with Marin to talk about that and you know there's sort of this mentality of looking at .com first or leading with .com for scalability and I just it's not really Chris to me where we're going from making sure that we're you know how we approach me and show that we intact scalability for .com if we're starting with .com or restarting somewhere else um from a dog fooding perspective. I'm pretty sure the handbook says that we're meant to well least the guidelines used to be that for new features that were meant to be available on githlet.com and so opposed to that at the same time there used to be a production ready checklist um that I think the engineering team was responsible for I know that for when we launched a geo there was a production readiness process that we had to go through and certainly with Giddly we consider these things on the source code front we're regularly considering scale like moving terabytes of data from the database into object storage and considering all these sorts of things. Performance is very much a feature and should be considered that and um I think particularly in categories where adoption is still growing and at early stages of maturity performance like understandably is less of a concern because there's lower usage so like solving scale at like an enormous level doesn't make sense commercially like necessarily when usage is small so there is a bit of a juggling act here because we don't want to build a product for billions of users if there's only I don't know 20,000 users experimenting with our newest feature so there's an iterative approach that needs to be taken but I would agree that particularly coming from a team that's digging out a lot of technical debt and solving a lot of performance problems all the time we're probably historically not being very good at picking the right moment to pay off technical debt and address performance problems until they become fires so yeah so to to that point just real quick James and sorry Scott um I think some things are obvious like when we look at our progressive deliveries um strategy I think that we like if you look at something like feature flags or something like that like that's something that I think is going to be like I wouldn't imagine that that's not going to be a key feature that we're going to bring forward um so I feel like that should be a give me on whether adoption has yet struck or not but the second thing that is not clear to me like again when I was interviewing Marin about dog fooding is that I noticed that Marin's like we don't this isn't we weren't they didn't come to us first and so this is not scalable or this is not usable for us internally and so it's like the the approach and process moving forward to dog food in the right spots is not clear to me or you know what the best practice has been or if anybody's you know crack that yeah I can give a concrete example is I did a call with Marin a few months back around confidential merger quests um so we knew that customers wanted to resolve them we knew that we wanted to do that and that we're trying to get rid of dev.gillab.org so I had a video call with him and a bunch of async conversations with like well I've got these ideas for what a first iteration looks like and then we did a few calls and worked through them and worked out which were the things that needed to happen and so we're shipping the first iteration of that in 12.1 but we coordinated with them and spoke I spoke with Marin quite a lot to make sure whatever we were building was useful and would solve the security problems that they had as well as our own ones so yeah I agree it needs to be proactive we're not gonna ship something's useful or that the infrastructure team is gonna want to opt into unless we've had a conversation with them in advance all right it's at 130 set can I add one like last time point it's sometimes really important for customers as well that we're running it on getlab.com before they adopt it so one example is we built ssltls support in Giddily but it's not turned on in getlab.com and so the customer that we built it for isn't using it because they're waiting for our production team to turn it on because they want to see before they turn it on for their enormous instance have we actually proven it at the world's largest getlab instance scale so I think that's one important reason why we always need to make sure that features are on and are getting used on getlab.com. Just forget it again my rimp sorry I got a couple of things I think we definitely have a stronger definition that I've done as part of progress is delivery right and so part of something done is it needs to run at scale and getlab.com successfully and not below the cost model not below performance and if it does it's just getting to be reverted frankly and that should be the bar for getting features across the line that doesn't mean for new features you know that have low usage that you know I was they're impeccably quite small but these still it needs to be within reason I totally agree that you don't want to over build on the first iteration for planning for millions of users because that's just making a sense but yeah I think that's one aspect I think their aspect is that on your comment press run pricing and we can maybe have a fallout here on like a handbook update but I think it's interesting that customer ritual absorb the cost on self-managed of compute and so for them if they want to have a ridiculous number of you know mirrors then you know it's fine because they're paying for it so use cases on their dime and so maybe a way to think about this is to have some level of controls you can set if you want to use the several that sort of I don't have have some way to control that in a matter of behavior for when we're covering the cost of those things but yeah anyways thank you all great topic Christopher please pile on that issue with thoughts on how to how to handle this like you're suggesting on definition of done Josh all right Karina six and seven yes so I submitted an MR for the product template yesterday and we're going through this process of getting more self-organized in the release area and with our engineering and user design partners and you know one of the things that we recognize and it's documented in the issue below in number seven is you know one our delivery percentage has not been great what you heard me talk about but it has been a complete ramp that we need to self-organize around some method and what we found and sort of the last prioritization for a release scope is that we have a lot of oversized issues and features that you know honestly need a need a beat or a release to go through user research maybe look at the code if they've never seen the code you know reviewed that piece of code before or makes the recommendations on the best way to solve so I put some thinking around you know that sort of you know that dual track mindset dual track agile kind of launching off of what user experience has recently updated for dual track agile so feedback on that and then the second piece is that this experiment or running is releverging semi dual track agile approach just to organize our conversation how we open issues for areas that we need a discovery beat versus presenting an issue that is actually ready for delivery one thing that was interesting Scott we were talking about you know just the kickoff call and having some you know you know images and and more to share that's definitely where I think we'd like to be with release is getting ahead of that curve and really having some concrete understanding and prototypes of what we're trying to to present and deliver but when we looked at sort of kind of going through that process you know this is really four complex things or heavy lifting because you know it is about a 20 to 30 day lead time to commit so just and so we have some targets um to improve um you know our hypothesis on leveraging this um you can follow it there if you have input but um it could they kind of tie together but I love input on the handbook piece thank you Karina for creating these and sharing these I think you're on the right track um in parallel I've been working with like Christopher and Eric and Kristi to outline a high-level description of our software development life cycle which will have two tracks this is sort of competing content there or maybe or maybe they could be merged so thank you for doing this I may slow roll it a little bit to make sure that we have one way of describing the flow we'd like to go through but thank you very much for getting it kicked off any questions for Karina if not Josh what do you yeah just a risk announcement you just went through renamed the promised label to playing priority um general meaning is large of the same although we shouldn't be promising features and so this is just a way to flag it um and uh that way it's reminder for pms that this issue had some importance left with additional dependencies um and so just be aware of it um so you can feel free to use it um I did note in the label text that it should only be applied by product managers and in particular the responsible five manager for that section um so it shouldn't be applied by cams or anyone else so awesome I like that terminology a lot better thank you Josh all right five minutes of spare anything else if not have a great Tuesday what are yours